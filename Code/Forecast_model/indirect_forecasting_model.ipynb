{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 5\n",
    "data_train=pd.read_csv(f'share_info/5-fold/train_fold{fold}.csv')\n",
    "data_test=pd.read_csv(f'share_info/5-fold/test_fold{fold}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['DATETIME'] = pd.DatetimeIndex( data_train['DATETIME'])\n",
    "data_test['DATETIME'] = pd.DatetimeIndex( data_test['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['month'] = pd.DatetimeIndex( data_train['DATETIME']).month\n",
    "data_train['day'] = pd.DatetimeIndex( data_train['DATETIME']).day\n",
    "data_train['hour'] = pd.DatetimeIndex( data_train['DATETIME']).hour\n",
    "data_train['minute'] = pd.DatetimeIndex( data_train['DATETIME']).minute\n",
    "\n",
    "data_test['month'] = pd.DatetimeIndex( data_test['DATETIME']).month\n",
    "data_test['day'] = pd.DatetimeIndex( data_test['DATETIME']).day\n",
    "data_test['hour'] = pd.DatetimeIndex( data_test['DATETIME']).hour\n",
    "data_test['minute'] = pd.DatetimeIndex( data_test['DATETIME']).minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['EMA_08'] = data_train['I(t)'].ewm(alpha=0.8).mean()\n",
    "data_test['EMA_08'] = data_test['I(t)'].ewm(alpha=0.8).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I_clear sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iclr.ashrae = K.*exp(-B./sza);  K = 1663.52224574355; B = 0.739550805574049;\n",
    "# coefs. are from fitting with selected clearsky data\n",
    "def clearsky_cal(x):\n",
    "    if x > 0:\n",
    "        return 1663.52225*2.71828**(-0.73955/x)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,9):\n",
    "    data_train['I_clr(t+{})'.format(i)] = data_train['sza(t+{})'.format(i)].apply(clearsky_cal)\n",
    "    data_test['I_clr(t+{})'.format(i)] = data_test['sza(t+{})'.format(i)].apply(clearsky_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['I(t)', 'I(t-1)','I(t-2)', 'I(t-3)', 'I(t-4)', 'I(t-5)'\n",
    "                , 'I(t-6)', 'I(t-7)', \\\n",
    "                'I^(d-1)(t+1)', 'I^(d-1)(t+2)', 'I^(d-1)(t+3)','I^(d-1)(t+4)',\\\n",
    "                'I^(d-1)(t+5)', 'I^(d-1)(t+6)', 'I^(d-1)(t+7)','I^(d-1)(t+8)', \\\n",
    "                'sza(t+1)','sza(t+2)','sza(t+3)','sza(t+4)','sza(t+5)','sza(t+6)','sza(t+7)','sza(t+8)' \\\n",
    "               , 'EMA_08', 'RH(t)',\n",
    "               'I_clr(t+1)','I_clr(t+2)','I_clr(t+3)','I_clr(t+4)','I_clr(t+5)','I_clr(t+6)','I_clr(t+7)',\n",
    "                'I_clr(t+8)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['I(t+1)','I(t+2)','I(t+3)','I(t+4)','I(t+5)','I(t+6)','I(t+7)','I(t+8)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.set_index('DATETIME')\n",
    "data_train_dropna = data_train[feature_cols+targets].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.set_index('DATETIME')\n",
    "data_test_dropna = data_test[feature_cols+targets+['time']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def normalizer_std(X):\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(train_data,test_data,feature,label, std = True):\n",
    "    \n",
    "    x_train = train_data[feature].values\n",
    "    y_train = train_data[label].values \n",
    "    \n",
    "    x_test = test_data[feature].values\n",
    "    y_test = test_data[label].values\n",
    "    \n",
    "    if std :\n",
    "        x_scaler = normalizer_std(x_train)\n",
    "        x_train = x_scaler.transform(x_train)\n",
    "        x_test = x_scaler.transform(x_test)\n",
    "        \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare feature for each model\n",
    "morning, midday, evening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## morning 6:00 - 9:30\n",
    "<p> feature - focus on feature that indicate trend at the time of forecasts Iclr(t+k), I(d-1)(t+k), sza(t+k)\n",
    "<p>I(t+1) : execution time = 5.30 to 9.00 -- include I(t)\n",
    "<p>I(t+2) : execution time = 5.30 to 8.30\n",
    "<p>I(t+3) : execution time = 5.30 to 8.00\n",
    "<p>I(t+4) : execution time = 5.30 to 7.30\n",
    "<p>I(t+5) : execution time = 5.30 to 7.00\n",
    "<p>I(t+6) : execution time = 5.30 to 6.30\n",
    "<p>I(t+7) : execution time = 5.30 to 6.00\n",
    "<p>I(t+8) : execution time = 5.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['I(t+1)', 'I(t+2)', 'I(t+3)', 'I(t+4)', 'I(t+5)', 'I(t+6)', 'I(t+7)','I(t+8)']\n",
    "feature_dict_m = dict()\n",
    "label_dict_m = dict()\n",
    "for i in range(8):\n",
    "    feature_dict_m['feature_{}'.format(i+1)] =   [f'sza(t+{i+1})',f'I^(d-1)(t+{i+1})',f'I_clr(t+{i+1})', 'EMA_08']\n",
    "    label_dict_m['label_{}'.format(i+1)] = [labels[i]]\n",
    "feature_dict_m['feature_1'].append('I(t)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m1 = data_train.between_time('5:30','9:00')[feature_dict_m[f'feature_1'] + label_dict_m[f'label_1']]\n",
    "train_m2 = data_train.between_time('5:30','8:30')[feature_dict_m[f'feature_2'] + label_dict_m[f'label_2']]\n",
    "train_m3 = data_train.between_time('5:30','8:00')[feature_dict_m[f'feature_3'] + label_dict_m[f'label_3']]\n",
    "train_m4 = data_train.between_time('5:30','7:30')[feature_dict_m[f'feature_4'] + label_dict_m[f'label_4']]\n",
    "train_m5 = data_train.between_time('5:30','7:00')[feature_dict_m[f'feature_5'] + label_dict_m[f'label_5']]\n",
    "train_m6 = data_train.between_time('5:30','6:30')[feature_dict_m[f'feature_6'] + label_dict_m[f'label_6']]\n",
    "train_m7 = data_train.between_time('5:30','6:00')[feature_dict_m[f'feature_7'] + label_dict_m[f'label_7']]\n",
    "train_m8 = data_train.between_time('5:30','5:30')[feature_dict_m[f'feature_8'] + label_dict_m[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m1 = data_test.between_time('5:30','9:00')[feature_dict_m[f'feature_1'] + label_dict_m[f'label_1']]\n",
    "test_m2 = data_test.between_time('5:30','8:30')[feature_dict_m[f'feature_2'] + label_dict_m[f'label_2']]\n",
    "test_m3 = data_test.between_time('5:30','8:00')[feature_dict_m[f'feature_3'] + label_dict_m[f'label_3']]\n",
    "test_m4 = data_test.between_time('5:30','7:30')[feature_dict_m[f'feature_4'] + label_dict_m[f'label_4']]\n",
    "test_m5 = data_test.between_time('5:30','7:00')[feature_dict_m[f'feature_5'] + label_dict_m[f'label_5']]\n",
    "test_m6 = data_test.between_time('5:30','6:30')[feature_dict_m[f'feature_6'] + label_dict_m[f'label_6']]\n",
    "test_m7 = data_test.between_time('5:30','6:00')[feature_dict_m[f'feature_7'] + label_dict_m[f'label_7']]\n",
    "test_m8 = data_test.between_time('5:30','5:30')[feature_dict_m[f'feature_8'] + label_dict_m[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:08,  8.41s/it]\u001b[A\n",
      "2it [00:14,  7.82s/it]\u001b[A\n",
      "3it [00:20,  7.13s/it]\u001b[A\n",
      "4it [00:25,  6.41s/it]\u001b[A\n",
      "5it [00:28,  5.66s/it]\u001b[A\n",
      "6it [00:32,  4.87s/it]\u001b[A\n",
      "7it [00:34,  4.12s/it]\u001b[A\n",
      "8it [00:36,  4.51s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "yhat_train_m = []\n",
    "yhat_test_m = []\n",
    "idx_train_m = []\n",
    "idx_test_m = []\n",
    "y_train_m = []\n",
    "y_test_m= []\n",
    "\n",
    "train_list_m = [train_m1, train_m2, train_m3, train_m4, train_m5, train_m6, train_m7, train_m8]\n",
    "test_list_m = [test_m1, test_m2, test_m3, test_m4, test_m5, test_m6, test_m7, test_m8]\n",
    "i = 0\n",
    "for train,test in tqdm(zip(train_list_m, test_list_m)):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = pre_processing(train,test,feature_dict_m[f'feature_{i+1}'],\n",
    "                                                      label_dict_m[f'label_{i+1}'], std = False)\n",
    "    reg = RandomForestRegressor(n_estimators = 1000, max_depth=10,\n",
    "                                random_state = 1, min_samples_split=34, min_samples_leaf=16)\n",
    "    reg.fit(x_train, y_train.ravel())\n",
    "\n",
    "\n",
    "    yhat_train_m.append(reg.predict(x_train))\n",
    "    yhat_test_m.append(reg.predict(x_test))\n",
    "    \n",
    "    y_train_m.append(y_train)\n",
    "    y_test_m.append(y_test)\n",
    "    \n",
    "    idx_train_m.append(train.index)\n",
    "    idx_test_m.append(test.index)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_m1 = pd.DataFrame(yhat_train_m[0],columns=['I(t+1)'], index = idx_train_m[0])\n",
    "yhat_train_m2 = pd.DataFrame(yhat_train_m[1],columns=['I(t+2)'], index = idx_train_m[1])\n",
    "yhat_train_m3 = pd.DataFrame(yhat_train_m[2],columns=['I(t+3)'], index = idx_train_m[2])\n",
    "yhat_train_m4 = pd.DataFrame(yhat_train_m[3],columns=['I(t+4)'], index = idx_train_m[3])\n",
    "yhat_train_m5 = pd.DataFrame(yhat_train_m[4],columns=['I(t+5)'], index = idx_train_m[4])\n",
    "yhat_train_m6 = pd.DataFrame(yhat_train_m[5],columns=['I(t+6)'], index = idx_train_m[5])\n",
    "yhat_train_m7 = pd.DataFrame(yhat_train_m[6],columns=['I(t+7)'], index = idx_train_m[6])\n",
    "yhat_train_m8 = pd.DataFrame(yhat_train_m[7],columns=['I(t+8)'], index = idx_train_m[7])\n",
    "\n",
    "y_train_m1 = pd.DataFrame(y_train_m[0],columns=['I(t+1)'], index = idx_train_m[0])\n",
    "y_train_m2 = pd.DataFrame(y_train_m[1],columns=['I(t+2)'], index = idx_train_m[1])\n",
    "y_train_m3 = pd.DataFrame(y_train_m[2],columns=['I(t+3)'], index = idx_train_m[2])\n",
    "y_train_m4 = pd.DataFrame(y_train_m[3],columns=['I(t+4)'], index = idx_train_m[3])\n",
    "y_train_m5 = pd.DataFrame(y_train_m[4],columns=['I(t+5)'], index = idx_train_m[4])\n",
    "y_train_m6 = pd.DataFrame(y_train_m[5],columns=['I(t+6)'], index = idx_train_m[5])\n",
    "y_train_m7 = pd.DataFrame(y_train_m[6],columns=['I(t+7)'], index = idx_train_m[6])\n",
    "y_train_m8 = pd.DataFrame(y_train_m[7],columns=['I(t+8)'], index = idx_train_m[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_m1 = pd.DataFrame(yhat_test_m[0],columns=['I(t+1)'], index = idx_test_m[0])\n",
    "yhat_test_m2 = pd.DataFrame(yhat_test_m[1],columns=['I(t+2)'], index = idx_test_m[1])\n",
    "yhat_test_m3 = pd.DataFrame(yhat_test_m[2],columns=['I(t+3)'], index = idx_test_m[2])\n",
    "yhat_test_m4 = pd.DataFrame(yhat_test_m[3],columns=['I(t+4)'], index = idx_test_m[3])\n",
    "yhat_test_m5 = pd.DataFrame(yhat_test_m[4],columns=['I(t+5)'], index = idx_test_m[4])\n",
    "yhat_test_m6 = pd.DataFrame(yhat_test_m[5],columns=['I(t+6)'], index = idx_test_m[5])\n",
    "yhat_test_m7 = pd.DataFrame(yhat_test_m[6],columns=['I(t+7)'], index = idx_test_m[6])\n",
    "yhat_test_m8 = pd.DataFrame(yhat_test_m[7],columns=['I(t+8)'], index = idx_test_m[7])\n",
    "\n",
    "y_test_m1 = pd.DataFrame(y_test_m[0],columns=['I(t+1)'], index = idx_test_m[0])\n",
    "y_test_m2 = pd.DataFrame(y_test_m[1],columns=['I(t+2)'], index = idx_test_m[1])\n",
    "y_test_m3 = pd.DataFrame(y_test_m[2],columns=['I(t+3)'], index = idx_test_m[2])\n",
    "y_test_m4 = pd.DataFrame(y_test_m[3],columns=['I(t+4)'], index = idx_test_m[3])\n",
    "y_test_m5 = pd.DataFrame(y_test_m[4],columns=['I(t+5)'], index = idx_test_m[4])\n",
    "y_test_m6 = pd.DataFrame(y_test_m[5],columns=['I(t+6)'], index = idx_test_m[5])\n",
    "y_test_m7 = pd.DataFrame(y_test_m[6],columns=['I(t+7)'], index = idx_test_m[6])\n",
    "y_test_m8 = pd.DataFrame(y_test_m[7],columns=['I(t+8)'], index = idx_test_m[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## afternoon 10:00 - 15.30\n",
    "feature - focus on both feature that indicate trend Iclr(t+k), I(d-1)(t+k), sza(t+k) and dynamic I(t),RH(t),..\n",
    "<p>I(t+1) : execution time = 9.30 to 15.00\n",
    "<p>I(t+2) : execution time = 9.00 to 14.30\n",
    "<p>I(t+3) : execution time = 8.30 to 14.00\n",
    "<p>I(t+4) : execution time = 8.00 to 13.30\n",
    "<p>I(t+5) : execution time = 7.30 to 13.00\n",
    "<p>I(t+6) : execution time = 7.00 to 12.30\n",
    "<p>I(t+7) : execution time = 6.30 to 12.00\n",
    "<p>I(t+8) : execution time = 6.00 to 11.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['I(t+1)', 'I(t+2)', 'I(t+3)', 'I(t+4)', 'I(t+5)', 'I(t+6)', 'I(t+7)','I(t+8)']\n",
    "feature_dict_a = dict()\n",
    "label_dict_a = dict()\n",
    "for i in range(8):\n",
    "    feature_dict_a[f'feature_{i+1}'] =   [f'sza(t+{i+1})',f'I^(d-1)(t+{i+1})',f'I_clr(t+{i+1})',\n",
    "                                                  'EMA_08','I(t)', 'I(t-1)', 'I(t-2)', 'I(t-3)', 'I(t-4)']\n",
    "    label_dict_a[f'label_{i+1}'] = [labels[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a1 = data_train.between_time('9:30','15:00')[feature_dict_a[f'feature_1'] + label_dict_a[f'label_1']]\n",
    "train_a2 = data_train.between_time('9:00','14:30')[feature_dict_a[f'feature_2'] + label_dict_a[f'label_2']]\n",
    "train_a3 = data_train.between_time('8:30','14:00')[feature_dict_a[f'feature_3'] + label_dict_a[f'label_3']]\n",
    "train_a4 = data_train.between_time('8:00','13:30')[feature_dict_a[f'feature_4'] + label_dict_a[f'label_4']]\n",
    "train_a5 = data_train.between_time('7:30','13:00')[feature_dict_a[f'feature_5'] + label_dict_a[f'label_5']]\n",
    "train_a6 = data_train.between_time('7:00','12:30')[feature_dict_a[f'feature_6'] + label_dict_a[f'label_6']]\n",
    "train_a7 = data_train.between_time('6:30','12:00')[feature_dict_a[f'feature_7'] + label_dict_a[f'label_7']]\n",
    "train_a8 = data_train.between_time('6:00','11:30')[feature_dict_a[f'feature_8'] + label_dict_a[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a1 = data_test.between_time('9:30','15:00')[feature_dict_a[f'feature_1'] + label_dict_a[f'label_1']]\n",
    "test_a2 = data_test.between_time('9:00','14:30')[feature_dict_a[f'feature_2'] + label_dict_a[f'label_2']]\n",
    "test_a3 = data_test.between_time('8:30','14:00')[feature_dict_a[f'feature_3'] + label_dict_a[f'label_3']]\n",
    "test_a4 = data_test.between_time('8:00','13:30')[feature_dict_a[f'feature_4'] + label_dict_a[f'label_4']]\n",
    "test_a5 = data_test.between_time('7:30','13:00')[feature_dict_a[f'feature_5'] + label_dict_a[f'label_5']]\n",
    "test_a6 = data_test.between_time('7:00','12:30')[feature_dict_a[f'feature_6'] + label_dict_a[f'label_6']]\n",
    "test_a7 = data_test.between_time('6:30','12:00')[feature_dict_a[f'feature_7'] + label_dict_a[f'label_7']]\n",
    "test_a8 = data_test.between_time('6:00','11:30')[feature_dict_a[f'feature_8'] + label_dict_a[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:25, 25.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:52, 26.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [01:21, 26.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [01:50, 27.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [02:17, 27.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [02:48, 28.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [03:14, 27.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [03:42, 27.78s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "yhat_train_a = []\n",
    "yhat_test_a = []\n",
    "idx_train_a = []\n",
    "idx_test_a = []\n",
    "y_train_a = []\n",
    "y_test_a = []\n",
    "\n",
    "train_list_a = [train_a1, train_a2, train_a3, train_a4, train_a5, train_a6, train_a7, train_a8]\n",
    "test_list_a = [test_a1, test_a2, test_a3, test_a4, test_a5, test_a6, test_a7, test_a8]\n",
    "i = 0\n",
    "for train,test in tqdm(zip(train_list_a, test_list_a)):\n",
    "    x_train, x_test, y_train, y_test = pre_processing(train,test,feature_dict_a[f'feature_{i+1}'],\n",
    "                                                      label_dict_a[f'label_{i+1}'], std = False)\n",
    "    reg = RandomForestRegressor(n_estimators = 1000, max_depth=10,\n",
    "                                random_state = 1, min_samples_split=34, min_samples_leaf=16)\n",
    "    reg.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    yhat_train_a.append(reg.predict(x_train))\n",
    "    yhat_test_a.append(reg.predict(x_test))\n",
    "    \n",
    "    y_train_a.append(y_train)\n",
    "    y_test_a.append(y_test)   \n",
    "    \n",
    "    idx_train_a.append(train.index)\n",
    "    idx_test_a.append(test.index)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_a1 = pd.DataFrame(yhat_train_a[0],columns=['I(t+1)'], index = idx_train_a[0])\n",
    "yhat_train_a2 = pd.DataFrame(yhat_train_a[1],columns=['I(t+2)'], index = idx_train_a[1])\n",
    "yhat_train_a3 = pd.DataFrame(yhat_train_a[2],columns=['I(t+3)'], index = idx_train_a[2])\n",
    "yhat_train_a4 = pd.DataFrame(yhat_train_a[3],columns=['I(t+4)'], index = idx_train_a[3])\n",
    "yhat_train_a5 = pd.DataFrame(yhat_train_a[4],columns=['I(t+5)'], index = idx_train_a[4])\n",
    "yhat_train_a6 = pd.DataFrame(yhat_train_a[5],columns=['I(t+6)'], index = idx_train_a[5])\n",
    "yhat_train_a7 = pd.DataFrame(yhat_train_a[6],columns=['I(t+7)'], index = idx_train_a[6])\n",
    "yhat_train_a8 = pd.DataFrame(yhat_train_a[7],columns=['I(t+8)'], index = idx_train_a[7])\n",
    "\n",
    "y_train_a1 = pd.DataFrame(y_train_a[0],columns=['I(t+1)'], index = idx_train_a[0])\n",
    "y_train_a2 = pd.DataFrame(y_train_a[1],columns=['I(t+2)'], index = idx_train_a[1])\n",
    "y_train_a3 = pd.DataFrame(y_train_a[2],columns=['I(t+3)'], index = idx_train_a[2])\n",
    "y_train_a4 = pd.DataFrame(y_train_a[3],columns=['I(t+4)'], index = idx_train_a[3])\n",
    "y_train_a5 = pd.DataFrame(y_train_a[4],columns=['I(t+5)'], index = idx_train_a[4])\n",
    "y_train_a6 = pd.DataFrame(y_train_a[5],columns=['I(t+6)'], index = idx_train_a[5])\n",
    "y_train_a7 = pd.DataFrame(y_train_a[6],columns=['I(t+7)'], index = idx_train_a[6])\n",
    "y_train_a8 = pd.DataFrame(y_train_a[7],columns=['I(t+8)'], index = idx_train_a[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_a1 = pd.DataFrame(yhat_test_a[0],columns=['I(t+1)'], index = idx_test_a[0])\n",
    "yhat_test_a2 = pd.DataFrame(yhat_test_a[1],columns=['I(t+2)'], index = idx_test_a[1])\n",
    "yhat_test_a3 = pd.DataFrame(yhat_test_a[2],columns=['I(t+3)'], index = idx_test_a[2])\n",
    "yhat_test_a4 = pd.DataFrame(yhat_test_a[3],columns=['I(t+4)'], index = idx_test_a[3])\n",
    "yhat_test_a5 = pd.DataFrame(yhat_test_a[4],columns=['I(t+5)'], index = idx_test_a[4])\n",
    "yhat_test_a6 = pd.DataFrame(yhat_test_a[5],columns=['I(t+6)'], index = idx_test_a[5])\n",
    "yhat_test_a7 = pd.DataFrame(yhat_test_a[6],columns=['I(t+7)'], index = idx_test_a[6])\n",
    "yhat_test_a8 = pd.DataFrame(yhat_test_a[7],columns=['I(t+8)'], index = idx_test_a[7])\n",
    "\n",
    "y_test_a1 = pd.DataFrame(y_test_a[0],columns=['I(t+1)'], index = idx_test_a[0])\n",
    "y_test_a2 = pd.DataFrame(y_test_a[1],columns=['I(t+2)'], index = idx_test_a[1])\n",
    "y_test_a3 = pd.DataFrame(y_test_a[2],columns=['I(t+3)'], index = idx_test_a[2])\n",
    "y_test_a4 = pd.DataFrame(y_test_a[3],columns=['I(t+4)'], index = idx_test_a[3])\n",
    "y_test_a5 = pd.DataFrame(y_test_a[4],columns=['I(t+5)'], index = idx_test_a[4])\n",
    "y_test_a6 = pd.DataFrame(y_test_a[5],columns=['I(t+6)'], index = idx_test_a[5])\n",
    "y_test_a7 = pd.DataFrame(y_test_a[6],columns=['I(t+7)'], index = idx_test_a[6])\n",
    "y_test_a8 = pd.DataFrame(y_test_a[7],columns=['I(t+8)'], index = idx_test_a[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evening 16:00 - 18:00\n",
    "feature - focus on  feature that indicate trend Iclr(t+k), I(d-1)(t+k), sza(t+k) \n",
    "<p>I(t+1) : execution time = 15.30 to 17.30\n",
    "<p>I(t+2) : execution time = 15.00 to 17.30\n",
    "<p>I(t+3) : execution time = 14.30 to 17.30\n",
    "<p>I(t+4) : execution time = 14.00 to 17.30\n",
    "<p>I(t+5) : execution time = 13.30 to 17.30\n",
    "<p>I(t+6) : execution time = 13.00 to 17.30\n",
    "<p>I(t+7) : execution time = 12.30 to 17.30\n",
    "<p>I(t+8) : execution time = 12.00 to 17.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['I(t+1)', 'I(t+2)', 'I(t+3)', 'I(t+4)', 'I(t+5)', 'I(t+6)', 'I(t+7)','I(t+8)']\n",
    "feature_dict_e = dict()\n",
    "label_dict_e = dict()\n",
    "for i in range(8):\n",
    "    feature_dict_e['feature_{}'.format(i+1)] =  [f'sza(t+{i+1})',f'I^(d-1)(t+{i+1})',f'I_clr(t+{i+1})', 'EMA_08', ]\n",
    "    label_dict_e['label_{}'.format(i+1)] = [labels[i]]\n",
    "feature_dict_e['feature_1'].append('I(t)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e1 = data_train.between_time('15:30','17:30')[feature_dict_e[f'feature_1'] + label_dict_e[f'label_1']]\n",
    "train_e2 = data_train.between_time('15:00','17:30')[feature_dict_e[f'feature_2'] + label_dict_e[f'label_2']]\n",
    "train_e3 = data_train.between_time('14:30','17:30')[feature_dict_e[f'feature_3'] + label_dict_e[f'label_3']]\n",
    "train_e4 = data_train.between_time('14:00','17:30')[feature_dict_e[f'feature_4'] + label_dict_e[f'label_4']]\n",
    "train_e5 = data_train.between_time('13:30','17:30')[feature_dict_e[f'feature_5'] + label_dict_e[f'label_5']]\n",
    "train_e6 = data_train.between_time('13:00','17:30')[feature_dict_e[f'feature_6'] + label_dict_e[f'label_6']]\n",
    "train_e7 = data_train.between_time('12:30','17:30')[feature_dict_e[f'feature_7'] + label_dict_e[f'label_7']]\n",
    "train_e8 = data_train.between_time('12:00','17:30')[feature_dict_e[f'feature_8'] + label_dict_e[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_e1 = data_test.between_time('15:30','17:30')[feature_dict_e[f'feature_1'] + label_dict_e[f'label_1']]\n",
    "test_e2 = data_test.between_time('15:00','17:30')[feature_dict_e[f'feature_2'] + label_dict_e[f'label_2']]\n",
    "test_e3 = data_test.between_time('14:30','17:30')[feature_dict_e[f'feature_3'] + label_dict_e[f'label_3']]\n",
    "test_e4 = data_test.between_time('14:00','17:30')[feature_dict_e[f'feature_4'] + label_dict_e[f'label_4']]\n",
    "test_e5 = data_test.between_time('13:30','17:30')[feature_dict_e[f'feature_5'] + label_dict_e[f'label_5']]\n",
    "test_e6 = data_test.between_time('13:00','17:30')[feature_dict_e[f'feature_6'] + label_dict_e[f'label_6']]\n",
    "test_e7 = data_test.between_time('12:30','17:30')[feature_dict_e[f'feature_7'] + label_dict_e[f'label_7']]\n",
    "test_e8 = data_test.between_time('12:00','17:30')[feature_dict_e[f'feature_8'] + label_dict_e[f'label_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:06,  6.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:12,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:18,  6.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:26,  6.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:36,  7.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:44,  7.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:55,  8.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [01:06,  8.25s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "yhat_train_e = []\n",
    "yhat_test_e = []\n",
    "idx_train_e = []\n",
    "idx_test_e = []\n",
    "y_train_e = []\n",
    "y_test_e = []\n",
    " \n",
    "train_list_e = [train_e1, train_e2, train_e3, train_e4, train_e5, train_e6, train_e7, train_e8]\n",
    "test_list_e = [test_e1, test_e2, test_e3, test_e4, test_e5, test_e6, test_e7, test_e8]\n",
    "i = 0\n",
    "for train,test in tqdm(zip(train_list_e, test_list_e)):\n",
    "    x_train, x_test, y_train, y_test = pre_processing(train,test,feature_dict_e[f'feature_{i+1}'],\n",
    "                                                      label_dict_e[f'label_{i+1}'], std = False)\n",
    "    reg = RandomForestRegressor(n_estimators = 1000, max_depth=10,\n",
    "                                random_state = 1, min_samples_split=34, min_samples_leaf=16)\n",
    "    reg.fit(x_train, y_train.ravel())\n",
    "    \n",
    "    yhat_train_e.append(reg.predict(x_train))\n",
    "    yhat_test_e.append(reg.predict(x_test))\n",
    "    \n",
    "    y_train_e.append(y_train)\n",
    "    y_test_e.append(y_test)\n",
    "    \n",
    "    idx_train_e.append(train.index)\n",
    "    idx_test_e.append(test.index)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train_e1 = pd.DataFrame(yhat_train_e[0],columns=['I(t+1)'], index = idx_train_e[0])\n",
    "yhat_train_e2 = pd.DataFrame(yhat_train_e[1],columns=['I(t+2)'], index = idx_train_e[1])\n",
    "yhat_train_e3 = pd.DataFrame(yhat_train_e[2],columns=['I(t+3)'], index = idx_train_e[2])\n",
    "yhat_train_e4 = pd.DataFrame(yhat_train_e[3],columns=['I(t+4)'], index = idx_train_e[3])\n",
    "yhat_train_e5 = pd.DataFrame(yhat_train_e[4],columns=['I(t+5)'], index = idx_train_e[4])\n",
    "yhat_train_e6 = pd.DataFrame(yhat_train_e[5],columns=['I(t+6)'], index = idx_train_e[5])\n",
    "yhat_train_e7 = pd.DataFrame(yhat_train_e[6],columns=['I(t+7)'], index = idx_train_e[6])\n",
    "yhat_train_e8 = pd.DataFrame(yhat_train_e[7],columns=['I(t+8)'], index = idx_train_e[7])\n",
    "\n",
    "y_train_e1 = pd.DataFrame(y_train_e[0],columns=['I(t+1)'], index = idx_train_e[0])\n",
    "y_train_e2 = pd.DataFrame(y_train_e[1],columns=['I(t+2)'], index = idx_train_e[1])\n",
    "y_train_e3 = pd.DataFrame(y_train_e[2],columns=['I(t+3)'], index = idx_train_e[2])\n",
    "y_train_e4 = pd.DataFrame(y_train_e[3],columns=['I(t+4)'], index = idx_train_e[3])\n",
    "y_train_e5 = pd.DataFrame(y_train_e[4],columns=['I(t+5)'], index = idx_train_e[4])\n",
    "y_train_e6 = pd.DataFrame(y_train_e[5],columns=['I(t+6)'], index = idx_train_e[5])\n",
    "y_train_e7 = pd.DataFrame(y_train_e[6],columns=['I(t+7)'], index = idx_train_e[6])\n",
    "y_train_e8 = pd.DataFrame(y_train_e[7],columns=['I(t+8)'], index = idx_train_e[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test_e1 = pd.DataFrame(yhat_test_e[0],columns=['I(t+1)'], index = idx_test_e[0])\n",
    "yhat_test_e2 = pd.DataFrame(yhat_test_e[1],columns=['I(t+2)'], index = idx_test_e[1])\n",
    "yhat_test_e3 = pd.DataFrame(yhat_test_e[2],columns=['I(t+3)'], index = idx_test_e[2])\n",
    "yhat_test_e4 = pd.DataFrame(yhat_test_e[3],columns=['I(t+4)'], index = idx_test_e[3])\n",
    "yhat_test_e5 = pd.DataFrame(yhat_test_e[4],columns=['I(t+5)'], index = idx_test_e[4])\n",
    "yhat_test_e6 = pd.DataFrame(yhat_test_e[5],columns=['I(t+6)'], index = idx_test_e[5])\n",
    "yhat_test_e7 = pd.DataFrame(yhat_test_e[6],columns=['I(t+7)'], index = idx_test_e[6])\n",
    "yhat_test_e8 = pd.DataFrame(yhat_test_e[7],columns=['I(t+8)'], index = idx_test_e[7])\n",
    "\n",
    "y_test_e1 = pd.DataFrame(y_test_e[0],columns=['I(t+1)'], index = idx_test_e[0])\n",
    "y_test_e2 = pd.DataFrame(y_test_e[1],columns=['I(t+2)'], index = idx_test_e[1])\n",
    "y_test_e3 = pd.DataFrame(y_test_e[2],columns=['I(t+3)'], index = idx_test_e[2])\n",
    "y_test_e4 = pd.DataFrame(y_test_e[3],columns=['I(t+4)'], index = idx_test_e[3])\n",
    "y_test_e5 = pd.DataFrame(y_test_e[4],columns=['I(t+5)'], index = idx_test_e[4])\n",
    "y_test_e6 = pd.DataFrame(y_test_e[5],columns=['I(t+6)'], index = idx_test_e[5])\n",
    "y_test_e7 = pd.DataFrame(y_test_e[6],columns=['I(t+7)'], index = idx_test_e[6])\n",
    "y_test_e8 = pd.DataFrame(y_test_e[7],columns=['I(t+8)'], index = idx_test_e[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get yhat dataframe : merge all yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train1 = pd.concat([yhat_train_m1,yhat_train_a1,yhat_train_e1]).sort_index()\n",
    "yhat_train2 = pd.concat([yhat_train_m2,yhat_train_a2,yhat_train_e2]).sort_index()\n",
    "yhat_train3 = pd.concat([yhat_train_m3,yhat_train_a3,yhat_train_e3]).sort_index()\n",
    "yhat_train4 = pd.concat([yhat_train_m4,yhat_train_a4,yhat_train_e4]).sort_index()\n",
    "yhat_train5 = pd.concat([yhat_train_m5,yhat_train_a5,yhat_train_e5]).sort_index()\n",
    "yhat_train6 = pd.concat([yhat_train_m6,yhat_train_a6,yhat_train_e6]).sort_index()\n",
    "yhat_train7 = pd.concat([yhat_train_m7,yhat_train_a7,yhat_train_e7]).sort_index()\n",
    "yhat_train8 = pd.concat([yhat_train_m8,yhat_train_a8,yhat_train_e8]).sort_index()\n",
    "\n",
    "y_train1 = pd.concat([y_train_m1,y_train_a1,y_train_e1]).sort_index()\n",
    "y_train2 = pd.concat([y_train_m2,y_train_a2,y_train_e2]).sort_index()\n",
    "y_train3 = pd.concat([y_train_m3,y_train_a3,y_train_e3]).sort_index()\n",
    "y_train4 = pd.concat([y_train_m4,y_train_a4,y_train_e4]).sort_index()\n",
    "y_train5 = pd.concat([y_train_m5,y_train_a5,y_train_e5]).sort_index()\n",
    "y_train6 = pd.concat([y_train_m6,y_train_a6,y_train_e6]).sort_index()\n",
    "y_train7 = pd.concat([y_train_m7,y_train_a7,y_train_e7]).sort_index()\n",
    "y_train8 = pd.concat([y_train_m8,y_train_a8,y_train_e8]).sort_index()\n",
    "\n",
    "yhat_test1 = pd.concat([yhat_test_m1, yhat_test_a1, yhat_test_e1]).sort_index()\n",
    "yhat_test2 = pd.concat([yhat_test_m2, yhat_test_a2, yhat_test_e2]).sort_index()\n",
    "yhat_test3 = pd.concat([yhat_test_m3, yhat_test_a3, yhat_test_e3]).sort_index()\n",
    "yhat_test4 = pd.concat([yhat_test_m4, yhat_test_a4, yhat_test_e4]).sort_index()\n",
    "yhat_test5 = pd.concat([yhat_test_m5, yhat_test_a5, yhat_test_e5]).sort_index()\n",
    "yhat_test6 = pd.concat([yhat_test_m6, yhat_test_a6, yhat_test_e6]).sort_index()\n",
    "yhat_test7 = pd.concat([yhat_test_m7, yhat_test_a7, yhat_test_e7]).sort_index()\n",
    "yhat_test8 = pd.concat([yhat_test_m8, yhat_test_a8, yhat_test_e8]).sort_index()\n",
    "\n",
    "y_test1 = pd.concat([y_test_m1, y_test_a1, y_test_e1]).sort_index()\n",
    "y_test2 = pd.concat([y_test_m2, y_test_a2, y_test_e2]).sort_index()\n",
    "y_test3 = pd.concat([y_test_m3, y_test_a3, y_test_e3]).sort_index()\n",
    "y_test4 = pd.concat([y_test_m4, y_test_a4, y_test_e4]).sort_index()\n",
    "y_test5 = pd.concat([y_test_m5, y_test_a5, y_test_e5]).sort_index()\n",
    "y_test6 = pd.concat([y_test_m6, y_test_a6, y_test_e6]).sort_index()\n",
    "y_test7 = pd.concat([y_test_m7, y_test_a7, y_test_e7]).sort_index()\n",
    "y_test8 = pd.concat([y_test_m8, y_test_a8, y_test_e8]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhat_train = [yhat_train1, yhat_train2, yhat_train3, yhat_train4, yhat_train5, yhat_train6, yhat_train7, yhat_train8]\n",
    "dfhat_test = [yhat_test1, yhat_test2, yhat_test3, yhat_test4, yhat_test5, yhat_test6, yhat_test7, yhat_test8]\n",
    "\n",
    "df_train = [y_train1, y_train2, y_train3, y_train4, y_train5, y_train6, y_train7, y_train8]\n",
    "df_test = [y_test1, y_test2, y_test3, y_test4, y_test5, y_test6, y_test7, y_test8]\n",
    "\n",
    "y_hat_train = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True, how='outer'), dfhat_train)\n",
    "y_hat_test = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True, how='outer'), dfhat_test)\n",
    "\n",
    "y_train = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True, how='outer'), df_train)\n",
    "y_test = reduce(lambda  left,right: pd.merge(left,right,left_index=True, right_index=True, how='outer'), df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train.dropna(inplace = True)\n",
    "y_hat_test.dropna(inplace = True)\n",
    "y_train.dropna(inplace = True)\n",
    "y_test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSETable_1( y_train, y_hat_train, y_test, y_hat_test, targets, train = True ):\n",
    "    time_list = ['5:30','6:00','6:30','7:00','7:30','8:00','8:30','9:00','9:30','10:00','10:30','11:00','11:30',\\\n",
    "            '12:00','12:30','13:00','13:30','14:00','14:30','15:00','15:30','16:00','16:30','17:00', '17:30']\n",
    "    table = pd.DataFrame({'Execution Time': time_list})\n",
    "    for i in targets:\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        for j in time_list:\n",
    "            temp1.append (np.sqrt(MSE(y_train[i].between_time(j, j), y_hat_train[i].between_time(j, j))))\n",
    "            temp2.append (np.sqrt(MSE(y_test[i].between_time(j, j), y_hat_test[i].between_time(j, j))))\n",
    "        if train == True:\n",
    "            table[i+'RMSE_train'] = temp1\n",
    "        table[i+'RMSE_test'] = temp2\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSETable_2( y_hat_train, y_hat_test, train_on = True):\n",
    "    time_list = ['6:00','6:30','7:00','7:30','8:00','8:30','9:00','9:30','10:00','10:30','11:00','11:30',\\\n",
    "            '12:00','12:30','13:00','13:30','14:00','14:30','15:00','15:30','16:00','16:30','17:00', '17:30']\n",
    "    table = pd.DataFrame({'Time of forecasted value I(t)': time_list})\n",
    "    for i in range(1, 9):\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        for j in time_list:\n",
    "            if train_on == True:\n",
    "                temp1.append (np.sqrt(np.nanmean( (y_hat_train['Step-{}'.format(i)].between_time(j, j) - y_hat_train['I_mea'].between_time(j, j))**2)))\n",
    "            temp2.append (np.sqrt(np.nanmean( (y_hat_test['Step-{}'.format(i)].between_time(j, j) - y_hat_test['I_mea'].between_time(j, j))**2)))\n",
    "        if train_on == True:\n",
    "            table['Step-{}_train'.format(i)] = temp1\n",
    "        table['Step-{}_test'.format(i)] = temp2\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSESummary_1( y_train, y_hat_train, y_test, y_hat_test, targets):\n",
    "    table = pd.DataFrame({'Step': targets})\n",
    "    train=[]\n",
    "    test=[]\n",
    "    for i in range(1,9):\n",
    "        train.append (np.sqrt(MSE(y_train['I(t+{})'.format(i)], y_hat_train['I(t+{})'.format(i)])))\n",
    "        test.append (np.sqrt(MSE(y_test['I(t+{})'.format(i)], y_hat_test['I(t+{})'.format(i)])))\n",
    "    table['train'] = train\n",
    "    table['test'] = test      \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_transform( table_input ):\n",
    "    table_input['DATE'] = table_input.index.date\n",
    "    table = pd.DataFrame({'Time of forecasted value': table_input.index})\n",
    "    for i in range(1,9):\n",
    "        table['Step-{}'.format(i)] = table_input.groupby('DATE').shift(i)['I(t+{})'.format(i)].values\n",
    "    table = table.set_index('Time of forecasted value')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_table_1 = RMSETable_1(y_train, y_hat_train, y_test, y_hat_test, targets, train =False)\n",
    "RMSE_table_sum = RMSESummary_1(y_train, y_hat_train, y_test, y_hat_test, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_T = table_transform(y_train)\n",
    "y_hat_train_T = table_transform(y_hat_train)\n",
    "Y_test_T = table_transform(y_test)\n",
    "y_hat_test_T = table_transform(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_T['I_mea'] = data_train['I(t)']\n",
    "y_hat_train_T['I_mea'] = data_train['I(t)']\n",
    "Y_test_T['I_mea'] = data_test['I(t)']\n",
    "y_hat_test_T['I_mea'] = data_test['I(t)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: Mean of empty slice\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "RMSE_table_2 = RMSETable_2(y_hat_train_T, y_hat_test_T, train_on =False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_train[['I(t)', 'P(t)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df['I(t)^2'] = df['I(t)']**2\n",
    "df['I(t)^3'] = df['I(t)']**3\n",
    "df['P(t)'] = df['P(t)']\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_I2P  = LinearRegression().fit(df[['I(t)', 'I(t)^2', 'I(t)^3']], df[['P(t)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.48970314e-03,  7.06825811e-06, -6.35211588e-09]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_I2P.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert I to P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_list =['P(t+1)', 'P(t+2)','P(t+3)','P(t+4)','P(t+5)','P(t+6)','P(t+7)','P(t+8)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat I^2 I^3\n",
    "for i in range(1, 9):\n",
    "    y_hat_test['I(t+{})^2'.format(i)] =  y_hat_test['I(t+{})'.format(i)]**2\n",
    "    y_hat_test['I(t+{})^3'.format(i)] =  y_hat_test['I(t+{})'.format(i)]**3\n",
    "    y_hat_train['I(t+{})^2'.format(i)] =  y_hat_train['I(t+{})'.format(i)]**2\n",
    "    y_hat_train['I(t+{})^3'.format(i)] =  y_hat_train['I(t+{})'.format(i)]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 9):\n",
    "    y_hat_test['P(t+{})'.format(i)] = model_I2P.predict( y_hat_test[ ['I(t+{})'.format(i), 'I(t+{})^2'.format(i), 'I(t+{})^3'.format(i)] ] )\n",
    "    y_hat_train['P(t+{})'.format(i)] = model_I2P.predict( y_hat_train[ ['I(t+{})'.format(i), 'I(t+{})^2'.format(i), 'I(t+{})^3'.format(i)] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_full = y_hat_test.merge(data_test[convert_list], left_index=True, right_index = True )\n",
    "data_train_full = y_hat_train.merge(data_train[convert_list], left_index=True, right_index = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate NRMSE Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NRMSE_P_Table_1( data_train, data_test, targets, train = True ):\n",
    "    time_list = ['5:30','6:00','6:30','7:00','7:30','8:00','8:30','9:00','9:30','10:00','10:30','11:00','11:30',\\\n",
    "            '12:00','12:30','13:00','13:30','14:00','14:30','15:00','15:30','16:00','16:30','17:00', '17:30']\n",
    "    data_train = data_train.dropna()\n",
    "    data_test = data_test.dropna()\n",
    "    table = pd.DataFrame({'Execution Time': time_list})\n",
    "    for i in targets:\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        for j in time_list:\n",
    "            temp1.append ( np.sqrt(MSE(data_train[i+'_x'].between_time(j, j), data_train[i+'_y'].between_time(j, j)))/8*100 )\n",
    "            temp2.append (np.sqrt(MSE(data_test[i+'_x'].between_time(j, j), data_test[i+'_y'].between_time(j, j)))/8*100)\n",
    "        if train == True:\n",
    "            table[i+'NRMSE_train'] = temp1\n",
    "        table[i+'NRMSE_test'] = temp2\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_transformP( table_input):\n",
    "    table_input['DATE'] = table_input.index.date\n",
    "    table = pd.DataFrame({'Time of forecasted value P(t)': table_input.index})\n",
    "    table['P_mea'] = table_input.groupby('DATE').shift(1)['P(t+1)_y'.format(1)].values\n",
    "    for i in range(1,9):\n",
    "        table['Step-{}'.format(i)] = table_input.groupby('DATE').shift(i)['P(t+{})_x'.format(i)].values\n",
    "    table = table.set_index('Time of forecasted value P(t)')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NRMSE_P_Table_2( data_train, data_test, train_on = True ):\n",
    "    time_list = ['6:00','6:30','7:00','7:30','8:00','8:30','9:00','9:30','10:00','10:30','11:00','11:30',\\\n",
    "            '12:00','12:30','13:00','13:30','14:00','14:30','15:00','15:30','16:00','16:30','17:00', '17:30']\n",
    "    table = pd.DataFrame({'Time of forecasted values': time_list})\n",
    "    for i in range(1,9):\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        for j in time_list:\n",
    "            if train_on == True:\n",
    "                temp1.append (np.sqrt(np.nanmean( (data_train['Step-{}'.format(i)].between_time(j, j) - data_train['P_mea'].between_time(j, j) )**2))/8*100)\n",
    "            temp2.append (np.sqrt(np.nanmean( (data_test['Step-{}'.format(i)].between_time(j, j) - data_test['P_mea'].between_time(j, j))**2))/8*100)\n",
    "        if train_on == True:\n",
    "            table['Step-{}_train'.format(i)] = temp1\n",
    "        table['Step-{}_test'.format(i)] = temp2\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NRMSESummary_P( data_train, data_test, targets, train_on = True):\n",
    "    table = pd.DataFrame({'Step': targets})\n",
    "    data_train = data_train.dropna()\n",
    "    data_test = data_test.dropna()\n",
    "    train=[]\n",
    "    test=[]\n",
    "    for i in range(1,9):\n",
    "        train.append (np.sqrt(MSE(data_train['P(t+{})_x'.format(i)], data_train['P(t+{})_y'.format(i)]))/8*100)\n",
    "        test.append (np.sqrt(MSE(data_test['P(t+{})_x'.format(i)], data_test['P(t+{})_y'.format(i)]))/8*100)\n",
    "    if train_on == True:\n",
    "        table['train'] = train\n",
    "    table['test'] = test      \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRMSE_P_table_1 = NRMSE_P_Table_1( data_train_full, data_test_full, convert_list, train = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: Mean of empty slice\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "NRMSE_P_table_2 = NRMSE_P_Table_2( table_transformP( data_train_full ) , table_transformP( data_test_full), train_on = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NRMSE_table_sum = NRMSESummary_P(data_train_full, data_test_full, convert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablePformat2 = table_transformP( data_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RMSE_table_1.to_csv(f'svr_sep_indirect_Ir_t1_f{fold}.csv')\n",
    "RMSE_table_2.to_csv(f'svr_sep_indirect_Ir_t2_f{fold}.csv')\n",
    "RMSE_table_sum.to_csv(f'svr_sep_indirect_Ir_t3_f{fold}.csv')\n",
    "y_hat_test_T.to_csv(f'svr_sep_indirect_I_yhat_f{fold}.csv')\n",
    "\n",
    "NRMSE_P_table_1.to_csv(f'svr_sep_indirect_P_t1_f{fold}.csv')\n",
    "NRMSE_P_table_2.to_csv(f'svr_sep_indirect_P_t2_f{fold}.csv')\n",
    "NRMSE_table_sum.to_csv(f'svr_sep_indirect_P_t3_f{fold}.csv')\n",
    "tablePformat2.to_csv(f'svr_sep_indirect_P_yhat_f{fold}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
